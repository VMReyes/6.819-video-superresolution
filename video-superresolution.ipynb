{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f8943e",
   "metadata": {},
   "source": [
    "# Video Super Resolution\n",
    "\n",
    "## By Daniel Shkreli and Victor Reyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd443c",
   "metadata": {},
   "source": [
    "### Import what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a277c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.57.0)\n",
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import lpips\n",
    "import torchvision\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "from torchvision import datasets, models, transforms\n",
    "!pip install tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b884ed7",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "To do this, we will be downloading the videos of the National Geographic channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fffb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d3231439944d52b35e80cb0a2b51aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/io/video.py:107: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"follow-up version. Please use pts_unit 'sec'.\")\n"
     ]
    }
   ],
   "source": [
    "sample_video_filename = \"yt-dls/train/0/Secrets of the Whales _ Official Trailer _ Disney+.mp4\"\n",
    "sample_video = VideoClips([sample_video_filename], clip_length_in_frames=10, frames_between_clips=10, frame_rate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19ca1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a datapoint\n",
    "# clip = sample_video.get_clip(0)[0]\n",
    "# frame_0 = clip[0]\n",
    "# print(frame_0.shape)\n",
    "# transformed_frame = torch.unsqueeze(data_transforms['train'](frame_0), 0)\n",
    "# print(transformed_frame.shape)\n",
    "# latent = torch.unsqueeze(torch.unsqueeze(resnet(transformed_frame),-1),-1)\n",
    "# print(latent.shape)\n",
    "# print(decoder(latent).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c00196",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "We will use resnet 18, pretrained at first.\n",
    "from https://github.com/hsinyilin19/ResNetVAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0ee5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_resnet_model(resume_from = None):\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    out_size = resnet.fc.in_features\n",
    "    print(\"out_size:\", out_size)\n",
    "    layers = []\n",
    "    for child in resnet.children():\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        layers.append(child)\n",
    "    resnet = nn.Sequential(*layers[:-1])\n",
    "    \n",
    "    #resnet.fc =  # create latent\n",
    "    \n",
    "    #resnet.add_module(\"bottleneck\", nn.Sequential()\n",
    "    if resume_from is not None:\n",
    "        print(f\"Loading weights from {resume_from}\")\n",
    "        model.load_state_dict(torch.load(resume_from))\n",
    "    return resnet, out_size\n",
    "\n",
    "def initialize_bottleneck(input_size, latent_size=1024):\n",
    "    bottleneck = nn.Sequential(nn.Linear(input_size, latent_size),\n",
    "                               nn.BatchNorm1d(latent_size, momentum=0.01))\n",
    "    return bottleneck\n",
    "\n",
    "def initialize_decoder():\n",
    "    stride = (2,2)\n",
    "    padding = (1,1)\n",
    "    convTrans6 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=1024, out_channels=1024, kernel_size=(4,4), stride=(1,1),\n",
    "                           padding=(0,0)),\n",
    "        nn.BatchNorm2d(1024, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    convTrans7 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(512, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    convTrans8 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(256, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    convTrans9 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(128, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    convTrans10 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(64, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "   \n",
    "    convTrans11 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(64, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    convTrans12 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(32, momentum=0.01),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    convTrans13 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=(4,4), stride=stride,\n",
    "                           padding=padding),\n",
    "        nn.BatchNorm2d(3, momentum=0.01),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    return nn.Sequential(convTrans6,\n",
    "                         convTrans7,\n",
    "                         convTrans8,\n",
    "                         convTrans9,\n",
    "                         convTrans10,\n",
    "                         convTrans11,\n",
    "                         convTrans12,\n",
    "                         convTrans13) \n",
    "\n",
    "    \n",
    "def video_loader(filename):\n",
    "    clips = VideoClips([filename], clip_length_in_frames=10, frames_between_clips = 10, frame_rate=10)\n",
    "    \n",
    "    return clips.get_clip(clips.num_clips()//2)[0]# currently just return a clip \n",
    "input_size = 256\n",
    "data_transforms = {\n",
    "    'train_in': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomRotation([-30,30]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'train_target': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size*2),\n",
    "        transforms.CenterCrop(input_size*2),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomRotation([-30,30]),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "def get_dataloaders(batch_size, input_size = 256, shuffle = True):\n",
    "    train_dataset = datasets.DatasetFolder(root=\"yt-dls/train/\", loader=video_loader, extensions=(\"mp4\"))\n",
    "    val_dataset = datasets.DatasetFolder(root=\"yt-dls/val/\", loader=video_loader, extensions=(\"mp4\"))\n",
    "    test_dataset = datasets.DatasetFolder(root=\"yt-dls/test/\", loader=video_loader, extensions=(\"mp4\"))\n",
    "\n",
    "    dataloaders_dict = {'train': torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True),\n",
    "                       'val': torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True),\n",
    "                       'test': torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)}\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e528110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # TQDM has nice progress bars\n",
    "            for inputs, _ in tqdm(dataloaders[phase]):\n",
    "                #inputs2 = data_transforms['train'](inputs)\n",
    "                # we get 10, 720, 1280, 3\n",
    "                # for now, lets just get a single frame\n",
    "                # perform transform on input\n",
    "                transformed_input = data_transforms[phase](inputs)\n",
    "                label = inputs # this makes sense, should we perform any transforms?\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    prediction = model(inputs)\n",
    "                    preceptual_loss = percept(prediction, label)\n",
    "                    mse_loss = nn.mse(prediction, label)\n",
    "                    loss = alpha * perceptual_loss + beta * mse_loss\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                print(inputs2.shape)\n",
    "\n",
    "def make_optimizer(bottleneck, decoder):\n",
    "    # Get all the parameters\n",
    "    print(\"bottleneck params\", bottleneck.parameters())\n",
    "    print(\"decoder params\", decoder.parameters())\n",
    "    params_to_update = list(bottleneck.parameters()) + list(decoder.parameters())\n",
    "    print(\"Params to learn:\")\n",
    "    for name, param in bottleneck.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "    for name, param in decoder.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "    # Use SGD\n",
    "    optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "    #optimizer = optim.Adagrad(params_to_update, lr=0.001)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07555ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_one_point(resnet, bottleneck, decoder, point, in_transforms, target_transforms, iterations=1000):\n",
    "    batched_input_1 = []\n",
    "    batched_input_2 = []\n",
    "    batched_targets = []\n",
    "    for example in point:  \n",
    "        in_1 = in_transforms(example[0]) # frame_i-1\n",
    "        in_2 = in_transforms(example[1]) # frame_i\n",
    "        target = target_transforms(example[1])\n",
    "        batched_input_1.append(in_1)\n",
    "        batched_input_2.append(in_2)\n",
    "        batched_targets.append(target)\n",
    "    batched_input_1 = torch.stack(batched_input_1)\n",
    "    batched_input_2 = torch.stack(batched_input_2)\n",
    "    batched_targets = torch.stack(batched_targets)\n",
    "\n",
    "    optimizer = make_optimizer(bottleneck, decoder)\n",
    "    resnet.eval()\n",
    "    bottleneck.train()\n",
    "    decoder.train()\n",
    "    losses = []\n",
    "    for i in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            embedding_1 = resnet(batched_input_1)\n",
    "            embedding_2 = resnet(batched_input_2)\n",
    "            #print(\"embeddingshape\", embedding_1.shape)\n",
    "            cat_latent = torch.cat((embedding_1, embedding_2), dim=1)\n",
    "            moved_latent = torch.squeeze(cat_latent)\n",
    "            #print(\"cat\", cat_latent.shape)\n",
    "            #print(\"moved\", moved_latent.shape)\n",
    "\n",
    "            latent = bottleneck(moved_latent)\n",
    "            #print(\"latentshape\", latent.shape)\n",
    "            \n",
    "            prediction = decoder(latent.unsqueeze(-1).unsqueeze(-1))\n",
    "            #print(\"prediction\", prediction.shape)\n",
    "            #print(\"targets\", batched_targets.shape)\n",
    "            mse_loss = nn.MSELoss()\n",
    "            mse_loss_val = mse_loss(prediction, batched_targets)\n",
    "            loss = 1 * mse_loss_val\n",
    "            print(loss)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return [prediction, losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c2b4128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97849cdc93c145769384df77fc6af4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/io/video.py:107: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"follow-up version. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f0eed0b3cf40658ca4f926d722b57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a point\n",
    "sample_video_filename = \"yt-dls/train/0/Secrets of the Whales _ Official Trailer _ Disney+.mp4\"\n",
    "sample_video_filename2 = 'yt-dls/train/0/The Race For the COVID-19 Vaccine _ National Geographic.mp4'\n",
    "\n",
    "sample_video = VideoClips([sample_video_filename], clip_length_in_frames=2, frames_between_clips=10, frame_rate=10)\n",
    "sample_video2 = VideoClips([sample_video_filename2], clip_length_in_frames=2, frames_between_clips=10, frame_rate=10)\n",
    "\n",
    "clip = sample_video.get_clip(0)\n",
    "clip2 = sample_video2.get_clip(0)\n",
    "\n",
    "batched_point = [clip[0], clip2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af529e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_size: 512\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n",
      "bottleneck params <generator object Module.parameters at 0x7fc6b025e200>\n",
      "decoder params <generator object Module.parameters at 0x7fc6b025e200>\n",
      "Params to learn:\n",
      "\t 0.weight\n",
      "\t 0.bias\n",
      "\t 1.weight\n",
      "\t 1.bias\n",
      "\t 0.0.weight\n",
      "\t 0.0.bias\n",
      "\t 0.1.weight\n",
      "\t 0.1.bias\n",
      "\t 1.0.weight\n",
      "\t 1.0.bias\n",
      "\t 1.1.weight\n",
      "\t 1.1.bias\n",
      "\t 2.0.weight\n",
      "\t 2.0.bias\n",
      "\t 2.1.weight\n",
      "\t 2.1.bias\n",
      "\t 3.0.weight\n",
      "\t 3.0.bias\n",
      "\t 3.1.weight\n",
      "\t 3.1.bias\n",
      "\t 4.0.weight\n",
      "\t 4.0.bias\n",
      "\t 4.1.weight\n",
      "\t 4.1.bias\n",
      "\t 5.0.weight\n",
      "\t 5.0.bias\n",
      "\t 5.1.weight\n",
      "\t 5.1.bias\n",
      "\t 6.0.weight\n",
      "\t 6.0.bias\n",
      "\t 6.1.weight\n",
      "\t 6.1.bias\n",
      "\t 7.0.weight\n",
      "\t 7.0.bias\n",
      "\t 7.1.weight\n",
      "\t 7.1.bias\n",
      "tensor(0.1637, grad_fn=<MulBackward0>)\n",
      "tensor(0.1637, grad_fn=<MulBackward0>)\n",
      "tensor(0.1636, grad_fn=<MulBackward0>)\n",
      "tensor(0.1636, grad_fn=<MulBackward0>)\n",
      "tensor(0.1636, grad_fn=<MulBackward0>)\n",
      "tensor(0.1635, grad_fn=<MulBackward0>)\n",
      "tensor(0.1635, grad_fn=<MulBackward0>)\n",
      "tensor(0.1634, grad_fn=<MulBackward0>)\n",
      "tensor(0.1634, grad_fn=<MulBackward0>)\n",
      "tensor(0.1633, grad_fn=<MulBackward0>)\n",
      "tensor(0.1633, grad_fn=<MulBackward0>)\n",
      "tensor(0.1632, grad_fn=<MulBackward0>)\n",
      "tensor(0.1631, grad_fn=<MulBackward0>)\n",
      "tensor(0.1631, grad_fn=<MulBackward0>)\n",
      "tensor(0.1630, grad_fn=<MulBackward0>)\n",
      "tensor(0.1629, grad_fn=<MulBackward0>)\n",
      "tensor(0.1628, grad_fn=<MulBackward0>)\n",
      "tensor(0.1628, grad_fn=<MulBackward0>)\n",
      "tensor(0.1627, grad_fn=<MulBackward0>)\n",
      "tensor(0.1626, grad_fn=<MulBackward0>)\n",
      "tensor(0.1625, grad_fn=<MulBackward0>)\n",
      "tensor(0.1624, grad_fn=<MulBackward0>)\n",
      "tensor(0.1624, grad_fn=<MulBackward0>)\n",
      "tensor(0.1623, grad_fn=<MulBackward0>)\n",
      "tensor(0.1622, grad_fn=<MulBackward0>)\n",
      "tensor(0.1621, grad_fn=<MulBackward0>)\n",
      "tensor(0.1620, grad_fn=<MulBackward0>)\n",
      "tensor(0.1619, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1618, grad_fn=<MulBackward0>)\n",
      "tensor(0.1617, grad_fn=<MulBackward0>)\n",
      "tensor(0.1617, grad_fn=<MulBackward0>)\n",
      "tensor(0.1616, grad_fn=<MulBackward0>)\n",
      "tensor(0.1615, grad_fn=<MulBackward0>)\n",
      "tensor(0.1614, grad_fn=<MulBackward0>)\n",
      "tensor(0.1613, grad_fn=<MulBackward0>)\n",
      "tensor(0.1612, grad_fn=<MulBackward0>)\n",
      "tensor(0.1611, grad_fn=<MulBackward0>)\n",
      "tensor(0.1610, grad_fn=<MulBackward0>)\n",
      "tensor(0.1609, grad_fn=<MulBackward0>)\n",
      "tensor(0.1609, grad_fn=<MulBackward0>)\n",
      "tensor(0.1608, grad_fn=<MulBackward0>)\n",
      "tensor(0.1607, grad_fn=<MulBackward0>)\n",
      "tensor(0.1606, grad_fn=<MulBackward0>)\n",
      "tensor(0.1605, grad_fn=<MulBackward0>)\n",
      "tensor(0.1604, grad_fn=<MulBackward0>)\n",
      "tensor(0.1603, grad_fn=<MulBackward0>)\n",
      "tensor(0.1602, grad_fn=<MulBackward0>)\n",
      "tensor(0.1601, grad_fn=<MulBackward0>)\n",
      "tensor(0.1600, grad_fn=<MulBackward0>)\n",
      "tensor(0.1599, grad_fn=<MulBackward0>)\n",
      "tensor(0.1599, grad_fn=<MulBackward0>)\n",
      "tensor(0.1598, grad_fn=<MulBackward0>)\n",
      "tensor(0.1597, grad_fn=<MulBackward0>)\n",
      "tensor(0.1596, grad_fn=<MulBackward0>)\n",
      "tensor(0.1595, grad_fn=<MulBackward0>)\n",
      "tensor(0.1594, grad_fn=<MulBackward0>)\n",
      "tensor(0.1593, grad_fn=<MulBackward0>)\n",
      "tensor(0.1592, grad_fn=<MulBackward0>)\n",
      "tensor(0.1591, grad_fn=<MulBackward0>)\n",
      "tensor(0.1590, grad_fn=<MulBackward0>)\n",
      "tensor(0.1589, grad_fn=<MulBackward0>)\n",
      "tensor(0.1588, grad_fn=<MulBackward0>)\n",
      "tensor(0.1588, grad_fn=<MulBackward0>)\n",
      "tensor(0.1587, grad_fn=<MulBackward0>)\n",
      "tensor(0.1586, grad_fn=<MulBackward0>)\n",
      "tensor(0.1585, grad_fn=<MulBackward0>)\n",
      "tensor(0.1584, grad_fn=<MulBackward0>)\n",
      "tensor(0.1583, grad_fn=<MulBackward0>)\n",
      "tensor(0.1582, grad_fn=<MulBackward0>)\n",
      "tensor(0.1581, grad_fn=<MulBackward0>)\n",
      "tensor(0.1580, grad_fn=<MulBackward0>)\n",
      "tensor(0.1579, grad_fn=<MulBackward0>)\n",
      "tensor(0.1578, grad_fn=<MulBackward0>)\n",
      "tensor(0.1577, grad_fn=<MulBackward0>)\n",
      "tensor(0.1576, grad_fn=<MulBackward0>)\n",
      "tensor(0.1576, grad_fn=<MulBackward0>)\n",
      "tensor(0.1575, grad_fn=<MulBackward0>)\n",
      "tensor(0.1574, grad_fn=<MulBackward0>)\n",
      "tensor(0.1573, grad_fn=<MulBackward0>)\n",
      "tensor(0.1572, grad_fn=<MulBackward0>)\n",
      "tensor(0.1571, grad_fn=<MulBackward0>)\n",
      "tensor(0.1570, grad_fn=<MulBackward0>)\n",
      "tensor(0.1569, grad_fn=<MulBackward0>)\n",
      "tensor(0.1568, grad_fn=<MulBackward0>)\n",
      "tensor(0.1567, grad_fn=<MulBackward0>)\n",
      "tensor(0.1566, grad_fn=<MulBackward0>)\n",
      "tensor(0.1565, grad_fn=<MulBackward0>)\n",
      "tensor(0.1564, grad_fn=<MulBackward0>)\n",
      "tensor(0.1564, grad_fn=<MulBackward0>)\n",
      "tensor(0.1563, grad_fn=<MulBackward0>)\n",
      "tensor(0.1562, grad_fn=<MulBackward0>)\n",
      "tensor(0.1561, grad_fn=<MulBackward0>)\n",
      "tensor(0.1560, grad_fn=<MulBackward0>)\n",
      "tensor(0.1559, grad_fn=<MulBackward0>)\n",
      "tensor(0.1558, grad_fn=<MulBackward0>)\n",
      "tensor(0.1557, grad_fn=<MulBackward0>)\n",
      "tensor(0.1556, grad_fn=<MulBackward0>)\n",
      "tensor(0.1555, grad_fn=<MulBackward0>)\n",
      "tensor(0.1554, grad_fn=<MulBackward0>)\n",
      "tensor(0.1553, grad_fn=<MulBackward0>)\n",
      "tensor(0.1552, grad_fn=<MulBackward0>)\n",
      "tensor(0.1551, grad_fn=<MulBackward0>)\n",
      "tensor(0.1550, grad_fn=<MulBackward0>)\n",
      "tensor(0.1550, grad_fn=<MulBackward0>)\n",
      "tensor(0.1549, grad_fn=<MulBackward0>)\n",
      "tensor(0.1548, grad_fn=<MulBackward0>)\n",
      "tensor(0.1547, grad_fn=<MulBackward0>)\n",
      "tensor(0.1546, grad_fn=<MulBackward0>)\n",
      "tensor(0.1545, grad_fn=<MulBackward0>)\n",
      "tensor(0.1544, grad_fn=<MulBackward0>)\n",
      "tensor(0.1543, grad_fn=<MulBackward0>)\n",
      "tensor(0.1542, grad_fn=<MulBackward0>)\n",
      "tensor(0.1541, grad_fn=<MulBackward0>)\n",
      "tensor(0.1540, grad_fn=<MulBackward0>)\n",
      "tensor(0.1539, grad_fn=<MulBackward0>)\n",
      "tensor(0.1538, grad_fn=<MulBackward0>)\n",
      "tensor(0.1537, grad_fn=<MulBackward0>)\n",
      "tensor(0.1536, grad_fn=<MulBackward0>)\n",
      "tensor(0.1535, grad_fn=<MulBackward0>)\n",
      "tensor(0.1534, grad_fn=<MulBackward0>)\n",
      "tensor(0.1534, grad_fn=<MulBackward0>)\n",
      "tensor(0.1533, grad_fn=<MulBackward0>)\n",
      "tensor(0.1532, grad_fn=<MulBackward0>)\n",
      "tensor(0.1531, grad_fn=<MulBackward0>)\n",
      "tensor(0.1530, grad_fn=<MulBackward0>)\n",
      "tensor(0.1529, grad_fn=<MulBackward0>)\n",
      "tensor(0.1528, grad_fn=<MulBackward0>)\n",
      "tensor(0.1527, grad_fn=<MulBackward0>)\n",
      "tensor(0.1526, grad_fn=<MulBackward0>)\n",
      "tensor(0.1525, grad_fn=<MulBackward0>)\n",
      "tensor(0.1524, grad_fn=<MulBackward0>)\n",
      "tensor(0.1523, grad_fn=<MulBackward0>)\n",
      "tensor(0.1522, grad_fn=<MulBackward0>)\n",
      "tensor(0.1521, grad_fn=<MulBackward0>)\n",
      "tensor(0.1520, grad_fn=<MulBackward0>)\n",
      "tensor(0.1519, grad_fn=<MulBackward0>)\n",
      "tensor(0.1518, grad_fn=<MulBackward0>)\n",
      "tensor(0.1517, grad_fn=<MulBackward0>)\n",
      "tensor(0.1516, grad_fn=<MulBackward0>)\n",
      "tensor(0.1515, grad_fn=<MulBackward0>)\n",
      "tensor(0.1514, grad_fn=<MulBackward0>)\n",
      "tensor(0.1513, grad_fn=<MulBackward0>)\n",
      "tensor(0.1512, grad_fn=<MulBackward0>)\n",
      "tensor(0.1511, grad_fn=<MulBackward0>)\n",
      "tensor(0.1510, grad_fn=<MulBackward0>)\n",
      "tensor(0.1509, grad_fn=<MulBackward0>)\n",
      "tensor(0.1508, grad_fn=<MulBackward0>)\n",
      "tensor(0.1507, grad_fn=<MulBackward0>)\n",
      "tensor(0.1506, grad_fn=<MulBackward0>)\n",
      "tensor(0.1505, grad_fn=<MulBackward0>)\n",
      "tensor(0.1504, grad_fn=<MulBackward0>)\n",
      "tensor(0.1503, grad_fn=<MulBackward0>)\n",
      "tensor(0.1502, grad_fn=<MulBackward0>)\n",
      "tensor(0.1501, grad_fn=<MulBackward0>)\n",
      "tensor(0.1500, grad_fn=<MulBackward0>)\n",
      "tensor(0.1499, grad_fn=<MulBackward0>)\n",
      "tensor(0.1498, grad_fn=<MulBackward0>)\n",
      "tensor(0.1497, grad_fn=<MulBackward0>)\n",
      "tensor(0.1496, grad_fn=<MulBackward0>)\n",
      "tensor(0.1495, grad_fn=<MulBackward0>)\n",
      "tensor(0.1494, grad_fn=<MulBackward0>)\n",
      "tensor(0.1493, grad_fn=<MulBackward0>)\n",
      "tensor(0.1492, grad_fn=<MulBackward0>)\n",
      "tensor(0.1491, grad_fn=<MulBackward0>)\n",
      "tensor(0.1490, grad_fn=<MulBackward0>)\n",
      "tensor(0.1489, grad_fn=<MulBackward0>)\n",
      "tensor(0.1488, grad_fn=<MulBackward0>)\n",
      "tensor(0.1487, grad_fn=<MulBackward0>)\n",
      "tensor(0.1486, grad_fn=<MulBackward0>)\n",
      "tensor(0.1485, grad_fn=<MulBackward0>)\n",
      "tensor(0.1484, grad_fn=<MulBackward0>)\n",
      "tensor(0.1483, grad_fn=<MulBackward0>)\n",
      "tensor(0.1482, grad_fn=<MulBackward0>)\n",
      "tensor(0.1481, grad_fn=<MulBackward0>)\n",
      "tensor(0.1480, grad_fn=<MulBackward0>)\n",
      "tensor(0.1479, grad_fn=<MulBackward0>)\n",
      "tensor(0.1477, grad_fn=<MulBackward0>)\n",
      "tensor(0.1476, grad_fn=<MulBackward0>)\n",
      "tensor(0.1475, grad_fn=<MulBackward0>)\n",
      "tensor(0.1474, grad_fn=<MulBackward0>)\n",
      "tensor(0.1473, grad_fn=<MulBackward0>)\n",
      "tensor(0.1472, grad_fn=<MulBackward0>)\n",
      "tensor(0.1471, grad_fn=<MulBackward0>)\n",
      "tensor(0.1470, grad_fn=<MulBackward0>)\n",
      "tensor(0.1469, grad_fn=<MulBackward0>)\n",
      "tensor(0.1468, grad_fn=<MulBackward0>)\n",
      "tensor(0.1467, grad_fn=<MulBackward0>)\n",
      "tensor(0.1465, grad_fn=<MulBackward0>)\n",
      "tensor(0.1464, grad_fn=<MulBackward0>)\n",
      "tensor(0.1463, grad_fn=<MulBackward0>)\n",
      "tensor(0.1462, grad_fn=<MulBackward0>)\n",
      "tensor(0.1461, grad_fn=<MulBackward0>)\n",
      "tensor(0.1460, grad_fn=<MulBackward0>)\n",
      "tensor(0.1459, grad_fn=<MulBackward0>)\n",
      "tensor(0.1458, grad_fn=<MulBackward0>)\n",
      "tensor(0.1456, grad_fn=<MulBackward0>)\n",
      "tensor(0.1455, grad_fn=<MulBackward0>)\n",
      "tensor(0.1454, grad_fn=<MulBackward0>)\n",
      "tensor(0.1453, grad_fn=<MulBackward0>)\n",
      "tensor(0.1452, grad_fn=<MulBackward0>)\n",
      "tensor(0.1451, grad_fn=<MulBackward0>)\n",
      "tensor(0.1449, grad_fn=<MulBackward0>)\n",
      "tensor(0.1448, grad_fn=<MulBackward0>)\n",
      "tensor(0.1447, grad_fn=<MulBackward0>)\n",
      "tensor(0.1446, grad_fn=<MulBackward0>)\n",
      "tensor(0.1445, grad_fn=<MulBackward0>)\n",
      "tensor(0.1444, grad_fn=<MulBackward0>)\n",
      "tensor(0.1442, grad_fn=<MulBackward0>)\n",
      "tensor(0.1441, grad_fn=<MulBackward0>)\n",
      "tensor(0.1440, grad_fn=<MulBackward0>)\n",
      "tensor(0.1439, grad_fn=<MulBackward0>)\n",
      "tensor(0.1437, grad_fn=<MulBackward0>)\n",
      "tensor(0.1436, grad_fn=<MulBackward0>)\n",
      "tensor(0.1435, grad_fn=<MulBackward0>)\n",
      "tensor(0.1434, grad_fn=<MulBackward0>)\n",
      "tensor(0.1432, grad_fn=<MulBackward0>)\n",
      "tensor(0.1431, grad_fn=<MulBackward0>)\n",
      "tensor(0.1430, grad_fn=<MulBackward0>)\n",
      "tensor(0.1429, grad_fn=<MulBackward0>)\n",
      "tensor(0.1427, grad_fn=<MulBackward0>)\n",
      "tensor(0.1426, grad_fn=<MulBackward0>)\n",
      "tensor(0.1425, grad_fn=<MulBackward0>)\n",
      "tensor(0.1423, grad_fn=<MulBackward0>)\n",
      "tensor(0.1422, grad_fn=<MulBackward0>)\n",
      "tensor(0.1421, grad_fn=<MulBackward0>)\n",
      "tensor(0.1419, grad_fn=<MulBackward0>)\n",
      "tensor(0.1418, grad_fn=<MulBackward0>)\n",
      "tensor(0.1417, grad_fn=<MulBackward0>)\n",
      "tensor(0.1415, grad_fn=<MulBackward0>)\n",
      "tensor(0.1414, grad_fn=<MulBackward0>)\n",
      "tensor(0.1413, grad_fn=<MulBackward0>)\n",
      "tensor(0.1411, grad_fn=<MulBackward0>)\n",
      "tensor(0.1410, grad_fn=<MulBackward0>)\n",
      "tensor(0.1409, grad_fn=<MulBackward0>)\n",
      "tensor(0.1407, grad_fn=<MulBackward0>)\n",
      "tensor(0.1406, grad_fn=<MulBackward0>)\n",
      "tensor(0.1404, grad_fn=<MulBackward0>)\n",
      "tensor(0.1403, grad_fn=<MulBackward0>)\n",
      "tensor(0.1401, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1400, grad_fn=<MulBackward0>)\n",
      "tensor(0.1399, grad_fn=<MulBackward0>)\n",
      "tensor(0.1397, grad_fn=<MulBackward0>)\n",
      "tensor(0.1396, grad_fn=<MulBackward0>)\n",
      "tensor(0.1394, grad_fn=<MulBackward0>)\n",
      "tensor(0.1393, grad_fn=<MulBackward0>)\n",
      "tensor(0.1391, grad_fn=<MulBackward0>)\n",
      "tensor(0.1390, grad_fn=<MulBackward0>)\n",
      "tensor(0.1388, grad_fn=<MulBackward0>)\n",
      "tensor(0.1387, grad_fn=<MulBackward0>)\n",
      "tensor(0.1385, grad_fn=<MulBackward0>)\n",
      "tensor(0.1383, grad_fn=<MulBackward0>)\n",
      "tensor(0.1382, grad_fn=<MulBackward0>)\n",
      "tensor(0.1380, grad_fn=<MulBackward0>)\n",
      "tensor(0.1379, grad_fn=<MulBackward0>)\n",
      "tensor(0.1377, grad_fn=<MulBackward0>)\n",
      "tensor(0.1375, grad_fn=<MulBackward0>)\n",
      "tensor(0.1374, grad_fn=<MulBackward0>)\n",
      "tensor(0.1372, grad_fn=<MulBackward0>)\n",
      "tensor(0.1370, grad_fn=<MulBackward0>)\n",
      "tensor(0.1369, grad_fn=<MulBackward0>)\n",
      "tensor(0.1367, grad_fn=<MulBackward0>)\n",
      "tensor(0.1365, grad_fn=<MulBackward0>)\n",
      "tensor(0.1364, grad_fn=<MulBackward0>)\n",
      "tensor(0.1362, grad_fn=<MulBackward0>)\n",
      "tensor(0.1360, grad_fn=<MulBackward0>)\n",
      "tensor(0.1359, grad_fn=<MulBackward0>)\n",
      "tensor(0.1357, grad_fn=<MulBackward0>)\n",
      "tensor(0.1355, grad_fn=<MulBackward0>)\n",
      "tensor(0.1353, grad_fn=<MulBackward0>)\n",
      "tensor(0.1351, grad_fn=<MulBackward0>)\n",
      "tensor(0.1350, grad_fn=<MulBackward0>)\n",
      "tensor(0.1348, grad_fn=<MulBackward0>)\n",
      "tensor(0.1346, grad_fn=<MulBackward0>)\n",
      "tensor(0.1344, grad_fn=<MulBackward0>)\n",
      "tensor(0.1342, grad_fn=<MulBackward0>)\n",
      "tensor(0.1340, grad_fn=<MulBackward0>)\n",
      "tensor(0.1339, grad_fn=<MulBackward0>)\n",
      "tensor(0.1337, grad_fn=<MulBackward0>)\n",
      "tensor(0.1335, grad_fn=<MulBackward0>)\n",
      "tensor(0.1333, grad_fn=<MulBackward0>)\n",
      "tensor(0.1331, grad_fn=<MulBackward0>)\n",
      "tensor(0.1329, grad_fn=<MulBackward0>)\n",
      "tensor(0.1327, grad_fn=<MulBackward0>)\n",
      "tensor(0.1325, grad_fn=<MulBackward0>)\n",
      "tensor(0.1323, grad_fn=<MulBackward0>)\n",
      "tensor(0.1321, grad_fn=<MulBackward0>)\n",
      "tensor(0.1319, grad_fn=<MulBackward0>)\n",
      "tensor(0.1317, grad_fn=<MulBackward0>)\n",
      "tensor(0.1315, grad_fn=<MulBackward0>)\n",
      "tensor(0.1313, grad_fn=<MulBackward0>)\n",
      "tensor(0.1311, grad_fn=<MulBackward0>)\n",
      "tensor(0.1309, grad_fn=<MulBackward0>)\n",
      "tensor(0.1307, grad_fn=<MulBackward0>)\n",
      "tensor(0.1305, grad_fn=<MulBackward0>)\n",
      "tensor(0.1302, grad_fn=<MulBackward0>)\n",
      "tensor(0.1300, grad_fn=<MulBackward0>)\n",
      "tensor(0.1298, grad_fn=<MulBackward0>)\n",
      "tensor(0.1296, grad_fn=<MulBackward0>)\n",
      "tensor(0.1294, grad_fn=<MulBackward0>)\n",
      "tensor(0.1292, grad_fn=<MulBackward0>)\n",
      "tensor(0.1290, grad_fn=<MulBackward0>)\n",
      "tensor(0.1287, grad_fn=<MulBackward0>)\n",
      "tensor(0.1285, grad_fn=<MulBackward0>)\n",
      "tensor(0.1283, grad_fn=<MulBackward0>)\n",
      "tensor(0.1281, grad_fn=<MulBackward0>)\n",
      "tensor(0.1278, grad_fn=<MulBackward0>)\n",
      "tensor(0.1276, grad_fn=<MulBackward0>)\n",
      "tensor(0.1274, grad_fn=<MulBackward0>)\n",
      "tensor(0.1272, grad_fn=<MulBackward0>)\n",
      "tensor(0.1269, grad_fn=<MulBackward0>)\n",
      "tensor(0.1267, grad_fn=<MulBackward0>)\n",
      "tensor(0.1265, grad_fn=<MulBackward0>)\n",
      "tensor(0.1263, grad_fn=<MulBackward0>)\n",
      "tensor(0.1260, grad_fn=<MulBackward0>)\n",
      "tensor(0.1258, grad_fn=<MulBackward0>)\n",
      "tensor(0.1256, grad_fn=<MulBackward0>)\n",
      "tensor(0.1253, grad_fn=<MulBackward0>)\n",
      "tensor(0.1251, grad_fn=<MulBackward0>)\n",
      "tensor(0.1249, grad_fn=<MulBackward0>)\n",
      "tensor(0.1246, grad_fn=<MulBackward0>)\n",
      "tensor(0.1244, grad_fn=<MulBackward0>)\n",
      "tensor(0.1242, grad_fn=<MulBackward0>)\n",
      "tensor(0.1239, grad_fn=<MulBackward0>)\n",
      "tensor(0.1237, grad_fn=<MulBackward0>)\n",
      "tensor(0.1234, grad_fn=<MulBackward0>)\n",
      "tensor(0.1232, grad_fn=<MulBackward0>)\n",
      "tensor(0.1230, grad_fn=<MulBackward0>)\n",
      "tensor(0.1227, grad_fn=<MulBackward0>)\n",
      "tensor(0.1225, grad_fn=<MulBackward0>)\n",
      "tensor(0.1222, grad_fn=<MulBackward0>)\n",
      "tensor(0.1220, grad_fn=<MulBackward0>)\n",
      "tensor(0.1218, grad_fn=<MulBackward0>)\n",
      "tensor(0.1215, grad_fn=<MulBackward0>)\n",
      "tensor(0.1213, grad_fn=<MulBackward0>)\n",
      "tensor(0.1210, grad_fn=<MulBackward0>)\n",
      "tensor(0.1208, grad_fn=<MulBackward0>)\n",
      "tensor(0.1206, grad_fn=<MulBackward0>)\n",
      "tensor(0.1203, grad_fn=<MulBackward0>)\n",
      "tensor(0.1201, grad_fn=<MulBackward0>)\n",
      "tensor(0.1198, grad_fn=<MulBackward0>)\n",
      "tensor(0.1196, grad_fn=<MulBackward0>)\n",
      "tensor(0.1194, grad_fn=<MulBackward0>)\n",
      "tensor(0.1191, grad_fn=<MulBackward0>)\n",
      "tensor(0.1189, grad_fn=<MulBackward0>)\n",
      "tensor(0.1186, grad_fn=<MulBackward0>)\n",
      "tensor(0.1184, grad_fn=<MulBackward0>)\n",
      "tensor(0.1182, grad_fn=<MulBackward0>)\n",
      "tensor(0.1179, grad_fn=<MulBackward0>)\n",
      "tensor(0.1177, grad_fn=<MulBackward0>)\n",
      "tensor(0.1175, grad_fn=<MulBackward0>)\n",
      "tensor(0.1172, grad_fn=<MulBackward0>)\n",
      "tensor(0.1170, grad_fn=<MulBackward0>)\n",
      "tensor(0.1167, grad_fn=<MulBackward0>)\n",
      "tensor(0.1165, grad_fn=<MulBackward0>)\n",
      "tensor(0.1163, grad_fn=<MulBackward0>)\n",
      "tensor(0.1160, grad_fn=<MulBackward0>)\n",
      "tensor(0.1158, grad_fn=<MulBackward0>)\n",
      "tensor(0.1156, grad_fn=<MulBackward0>)\n",
      "tensor(0.1153, grad_fn=<MulBackward0>)\n",
      "tensor(0.1151, grad_fn=<MulBackward0>)\n",
      "tensor(0.1149, grad_fn=<MulBackward0>)\n",
      "tensor(0.1147, grad_fn=<MulBackward0>)\n",
      "tensor(0.1144, grad_fn=<MulBackward0>)\n",
      "tensor(0.1142, grad_fn=<MulBackward0>)\n",
      "tensor(0.1140, grad_fn=<MulBackward0>)\n",
      "tensor(0.1137, grad_fn=<MulBackward0>)\n",
      "tensor(0.1135, grad_fn=<MulBackward0>)\n",
      "tensor(0.1133, grad_fn=<MulBackward0>)\n",
      "tensor(0.1131, grad_fn=<MulBackward0>)\n",
      "tensor(0.1128, grad_fn=<MulBackward0>)\n",
      "tensor(0.1126, grad_fn=<MulBackward0>)\n",
      "tensor(0.1124, grad_fn=<MulBackward0>)\n",
      "tensor(0.1122, grad_fn=<MulBackward0>)\n",
      "tensor(0.1120, grad_fn=<MulBackward0>)\n",
      "tensor(0.1117, grad_fn=<MulBackward0>)\n",
      "tensor(0.1115, grad_fn=<MulBackward0>)\n",
      "tensor(0.1113, grad_fn=<MulBackward0>)\n",
      "tensor(0.1111, grad_fn=<MulBackward0>)\n",
      "tensor(0.1109, grad_fn=<MulBackward0>)\n",
      "tensor(0.1107, grad_fn=<MulBackward0>)\n",
      "tensor(0.1105, grad_fn=<MulBackward0>)\n",
      "tensor(0.1103, grad_fn=<MulBackward0>)\n",
      "tensor(0.1100, grad_fn=<MulBackward0>)\n",
      "tensor(0.1098, grad_fn=<MulBackward0>)\n",
      "tensor(0.1096, grad_fn=<MulBackward0>)\n",
      "tensor(0.1094, grad_fn=<MulBackward0>)\n",
      "tensor(0.1092, grad_fn=<MulBackward0>)\n",
      "tensor(0.1090, grad_fn=<MulBackward0>)\n",
      "tensor(0.1088, grad_fn=<MulBackward0>)\n",
      "tensor(0.1086, grad_fn=<MulBackward0>)\n",
      "tensor(0.1084, grad_fn=<MulBackward0>)\n",
      "tensor(0.1082, grad_fn=<MulBackward0>)\n",
      "tensor(0.1080, grad_fn=<MulBackward0>)\n",
      "tensor(0.1078, grad_fn=<MulBackward0>)\n",
      "tensor(0.1076, grad_fn=<MulBackward0>)\n",
      "tensor(0.1074, grad_fn=<MulBackward0>)\n",
      "tensor(0.1072, grad_fn=<MulBackward0>)\n",
      "tensor(0.1070, grad_fn=<MulBackward0>)\n",
      "tensor(0.1068, grad_fn=<MulBackward0>)\n",
      "tensor(0.1066, grad_fn=<MulBackward0>)\n",
      "tensor(0.1064, grad_fn=<MulBackward0>)\n",
      "tensor(0.1062, grad_fn=<MulBackward0>)\n",
      "tensor(0.1061, grad_fn=<MulBackward0>)\n",
      "tensor(0.1059, grad_fn=<MulBackward0>)\n",
      "tensor(0.1057, grad_fn=<MulBackward0>)\n",
      "tensor(0.1055, grad_fn=<MulBackward0>)\n",
      "tensor(0.1053, grad_fn=<MulBackward0>)\n",
      "tensor(0.1051, grad_fn=<MulBackward0>)\n",
      "tensor(0.1049, grad_fn=<MulBackward0>)\n",
      "tensor(0.1048, grad_fn=<MulBackward0>)\n",
      "tensor(0.1046, grad_fn=<MulBackward0>)\n",
      "tensor(0.1044, grad_fn=<MulBackward0>)\n",
      "tensor(0.1042, grad_fn=<MulBackward0>)\n",
      "tensor(0.1040, grad_fn=<MulBackward0>)\n",
      "tensor(0.1039, grad_fn=<MulBackward0>)\n",
      "tensor(0.1037, grad_fn=<MulBackward0>)\n",
      "tensor(0.1035, grad_fn=<MulBackward0>)\n",
      "tensor(0.1033, grad_fn=<MulBackward0>)\n",
      "tensor(0.1031, grad_fn=<MulBackward0>)\n",
      "tensor(0.1030, grad_fn=<MulBackward0>)\n",
      "tensor(0.1028, grad_fn=<MulBackward0>)\n",
      "tensor(0.1026, grad_fn=<MulBackward0>)\n",
      "tensor(0.1025, grad_fn=<MulBackward0>)\n",
      "tensor(0.1023, grad_fn=<MulBackward0>)\n",
      "tensor(0.1021, grad_fn=<MulBackward0>)\n",
      "tensor(0.1019, grad_fn=<MulBackward0>)\n",
      "tensor(0.1018, grad_fn=<MulBackward0>)\n",
      "tensor(0.1016, grad_fn=<MulBackward0>)\n",
      "tensor(0.1014, grad_fn=<MulBackward0>)\n",
      "tensor(0.1013, grad_fn=<MulBackward0>)\n",
      "tensor(0.1011, grad_fn=<MulBackward0>)\n",
      "tensor(0.1010, grad_fn=<MulBackward0>)\n",
      "tensor(0.1008, grad_fn=<MulBackward0>)\n",
      "tensor(0.1006, grad_fn=<MulBackward0>)\n",
      "tensor(0.1005, grad_fn=<MulBackward0>)\n",
      "tensor(0.1003, grad_fn=<MulBackward0>)\n",
      "tensor(0.1002, grad_fn=<MulBackward0>)\n",
      "tensor(0.1000, grad_fn=<MulBackward0>)\n",
      "tensor(0.0998, grad_fn=<MulBackward0>)\n",
      "tensor(0.0997, grad_fn=<MulBackward0>)\n",
      "tensor(0.0995, grad_fn=<MulBackward0>)\n",
      "tensor(0.0994, grad_fn=<MulBackward0>)\n",
      "tensor(0.0992, grad_fn=<MulBackward0>)\n",
      "tensor(0.0991, grad_fn=<MulBackward0>)\n",
      "tensor(0.0989, grad_fn=<MulBackward0>)\n",
      "tensor(0.0988, grad_fn=<MulBackward0>)\n",
      "tensor(0.0986, grad_fn=<MulBackward0>)\n",
      "tensor(0.0984, grad_fn=<MulBackward0>)\n",
      "tensor(0.0983, grad_fn=<MulBackward0>)\n",
      "tensor(0.0981, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0980, grad_fn=<MulBackward0>)\n",
      "tensor(0.0979, grad_fn=<MulBackward0>)\n",
      "tensor(0.0977, grad_fn=<MulBackward0>)\n",
      "tensor(0.0976, grad_fn=<MulBackward0>)\n",
      "tensor(0.0974, grad_fn=<MulBackward0>)\n",
      "tensor(0.0973, grad_fn=<MulBackward0>)\n",
      "tensor(0.0971, grad_fn=<MulBackward0>)\n",
      "tensor(0.0970, grad_fn=<MulBackward0>)\n",
      "tensor(0.0968, grad_fn=<MulBackward0>)\n",
      "tensor(0.0967, grad_fn=<MulBackward0>)\n",
      "tensor(0.0965, grad_fn=<MulBackward0>)\n",
      "tensor(0.0964, grad_fn=<MulBackward0>)\n",
      "tensor(0.0963, grad_fn=<MulBackward0>)\n",
      "tensor(0.0961, grad_fn=<MulBackward0>)\n",
      "tensor(0.0960, grad_fn=<MulBackward0>)\n",
      "tensor(0.0958, grad_fn=<MulBackward0>)\n",
      "tensor(0.0957, grad_fn=<MulBackward0>)\n",
      "tensor(0.0956, grad_fn=<MulBackward0>)\n",
      "tensor(0.0954, grad_fn=<MulBackward0>)\n",
      "tensor(0.0953, grad_fn=<MulBackward0>)\n",
      "tensor(0.0952, grad_fn=<MulBackward0>)\n",
      "tensor(0.0950, grad_fn=<MulBackward0>)\n",
      "tensor(0.0949, grad_fn=<MulBackward0>)\n",
      "tensor(0.0948, grad_fn=<MulBackward0>)\n",
      "tensor(0.0946, grad_fn=<MulBackward0>)\n",
      "tensor(0.0945, grad_fn=<MulBackward0>)\n",
      "tensor(0.0944, grad_fn=<MulBackward0>)\n",
      "tensor(0.0942, grad_fn=<MulBackward0>)\n",
      "tensor(0.0941, grad_fn=<MulBackward0>)\n",
      "tensor(0.0940, grad_fn=<MulBackward0>)\n",
      "tensor(0.0938, grad_fn=<MulBackward0>)\n",
      "tensor(0.0937, grad_fn=<MulBackward0>)\n",
      "tensor(0.0936, grad_fn=<MulBackward0>)\n",
      "tensor(0.0934, grad_fn=<MulBackward0>)\n",
      "tensor(0.0933, grad_fn=<MulBackward0>)\n",
      "tensor(0.0932, grad_fn=<MulBackward0>)\n",
      "tensor(0.0931, grad_fn=<MulBackward0>)\n",
      "tensor(0.0929, grad_fn=<MulBackward0>)\n",
      "tensor(0.0928, grad_fn=<MulBackward0>)\n",
      "tensor(0.0927, grad_fn=<MulBackward0>)\n",
      "tensor(0.0926, grad_fn=<MulBackward0>)\n",
      "tensor(0.0924, grad_fn=<MulBackward0>)\n",
      "tensor(0.0923, grad_fn=<MulBackward0>)\n",
      "tensor(0.0922, grad_fn=<MulBackward0>)\n",
      "tensor(0.0921, grad_fn=<MulBackward0>)\n",
      "tensor(0.0919, grad_fn=<MulBackward0>)\n",
      "tensor(0.0918, grad_fn=<MulBackward0>)\n",
      "tensor(0.0917, grad_fn=<MulBackward0>)\n",
      "tensor(0.0916, grad_fn=<MulBackward0>)\n",
      "tensor(0.0915, grad_fn=<MulBackward0>)\n",
      "tensor(0.0913, grad_fn=<MulBackward0>)\n",
      "tensor(0.0912, grad_fn=<MulBackward0>)\n",
      "tensor(0.0911, grad_fn=<MulBackward0>)\n",
      "tensor(0.0910, grad_fn=<MulBackward0>)\n",
      "tensor(0.0909, grad_fn=<MulBackward0>)\n",
      "tensor(0.0907, grad_fn=<MulBackward0>)\n",
      "tensor(0.0906, grad_fn=<MulBackward0>)\n",
      "tensor(0.0905, grad_fn=<MulBackward0>)\n",
      "tensor(0.0904, grad_fn=<MulBackward0>)\n",
      "tensor(0.0903, grad_fn=<MulBackward0>)\n",
      "tensor(0.0902, grad_fn=<MulBackward0>)\n",
      "tensor(0.0901, grad_fn=<MulBackward0>)\n",
      "tensor(0.0899, grad_fn=<MulBackward0>)\n",
      "tensor(0.0898, grad_fn=<MulBackward0>)\n",
      "tensor(0.0897, grad_fn=<MulBackward0>)\n",
      "tensor(0.0896, grad_fn=<MulBackward0>)\n",
      "tensor(0.0895, grad_fn=<MulBackward0>)\n",
      "tensor(0.0894, grad_fn=<MulBackward0>)\n",
      "tensor(0.0893, grad_fn=<MulBackward0>)\n",
      "tensor(0.0891, grad_fn=<MulBackward0>)\n",
      "tensor(0.0890, grad_fn=<MulBackward0>)\n",
      "tensor(0.0889, grad_fn=<MulBackward0>)\n",
      "tensor(0.0888, grad_fn=<MulBackward0>)\n",
      "tensor(0.0887, grad_fn=<MulBackward0>)\n",
      "tensor(0.0886, grad_fn=<MulBackward0>)\n",
      "tensor(0.0885, grad_fn=<MulBackward0>)\n",
      "tensor(0.0884, grad_fn=<MulBackward0>)\n",
      "tensor(0.0883, grad_fn=<MulBackward0>)\n",
      "tensor(0.0882, grad_fn=<MulBackward0>)\n",
      "tensor(0.0881, grad_fn=<MulBackward0>)\n",
      "tensor(0.0879, grad_fn=<MulBackward0>)\n",
      "tensor(0.0878, grad_fn=<MulBackward0>)\n",
      "tensor(0.0877, grad_fn=<MulBackward0>)\n",
      "tensor(0.0876, grad_fn=<MulBackward0>)\n",
      "tensor(0.0875, grad_fn=<MulBackward0>)\n",
      "tensor(0.0874, grad_fn=<MulBackward0>)\n",
      "tensor(0.0873, grad_fn=<MulBackward0>)\n",
      "tensor(0.0872, grad_fn=<MulBackward0>)\n",
      "tensor(0.0871, grad_fn=<MulBackward0>)\n",
      "tensor(0.0870, grad_fn=<MulBackward0>)\n",
      "tensor(0.0869, grad_fn=<MulBackward0>)\n",
      "tensor(0.0868, grad_fn=<MulBackward0>)\n",
      "tensor(0.0867, grad_fn=<MulBackward0>)\n",
      "tensor(0.0866, grad_fn=<MulBackward0>)\n",
      "tensor(0.0865, grad_fn=<MulBackward0>)\n",
      "tensor(0.0864, grad_fn=<MulBackward0>)\n",
      "tensor(0.0863, grad_fn=<MulBackward0>)\n",
      "tensor(0.0862, grad_fn=<MulBackward0>)\n",
      "tensor(0.0861, grad_fn=<MulBackward0>)\n",
      "tensor(0.0860, grad_fn=<MulBackward0>)\n",
      "tensor(0.0859, grad_fn=<MulBackward0>)\n",
      "tensor(0.0858, grad_fn=<MulBackward0>)\n",
      "tensor(0.0857, grad_fn=<MulBackward0>)\n",
      "tensor(0.0856, grad_fn=<MulBackward0>)\n",
      "tensor(0.0855, grad_fn=<MulBackward0>)\n",
      "tensor(0.0854, grad_fn=<MulBackward0>)\n",
      "tensor(0.0853, grad_fn=<MulBackward0>)\n",
      "tensor(0.0852, grad_fn=<MulBackward0>)\n",
      "tensor(0.0851, grad_fn=<MulBackward0>)\n",
      "tensor(0.0850, grad_fn=<MulBackward0>)\n",
      "tensor(0.0849, grad_fn=<MulBackward0>)\n",
      "tensor(0.0848, grad_fn=<MulBackward0>)\n",
      "tensor(0.0847, grad_fn=<MulBackward0>)\n",
      "tensor(0.0846, grad_fn=<MulBackward0>)\n",
      "tensor(0.0845, grad_fn=<MulBackward0>)\n",
      "tensor(0.0844, grad_fn=<MulBackward0>)\n",
      "tensor(0.0843, grad_fn=<MulBackward0>)\n",
      "tensor(0.0842, grad_fn=<MulBackward0>)\n",
      "tensor(0.0842, grad_fn=<MulBackward0>)\n",
      "tensor(0.0841, grad_fn=<MulBackward0>)\n",
      "tensor(0.0840, grad_fn=<MulBackward0>)\n",
      "tensor(0.0839, grad_fn=<MulBackward0>)\n",
      "tensor(0.0838, grad_fn=<MulBackward0>)\n",
      "tensor(0.0837, grad_fn=<MulBackward0>)\n",
      "tensor(0.0836, grad_fn=<MulBackward0>)\n",
      "tensor(0.0835, grad_fn=<MulBackward0>)\n",
      "tensor(0.0834, grad_fn=<MulBackward0>)\n",
      "tensor(0.0833, grad_fn=<MulBackward0>)\n",
      "tensor(0.0832, grad_fn=<MulBackward0>)\n",
      "tensor(0.0831, grad_fn=<MulBackward0>)\n",
      "tensor(0.0831, grad_fn=<MulBackward0>)\n",
      "tensor(0.0830, grad_fn=<MulBackward0>)\n",
      "tensor(0.0829, grad_fn=<MulBackward0>)\n",
      "tensor(0.0828, grad_fn=<MulBackward0>)\n",
      "tensor(0.0827, grad_fn=<MulBackward0>)\n",
      "tensor(0.0826, grad_fn=<MulBackward0>)\n",
      "tensor(0.0825, grad_fn=<MulBackward0>)\n",
      "tensor(0.0824, grad_fn=<MulBackward0>)\n",
      "tensor(0.0823, grad_fn=<MulBackward0>)\n",
      "tensor(0.0823, grad_fn=<MulBackward0>)\n",
      "tensor(0.0822, grad_fn=<MulBackward0>)\n",
      "tensor(0.0821, grad_fn=<MulBackward0>)\n",
      "tensor(0.0820, grad_fn=<MulBackward0>)\n",
      "tensor(0.0819, grad_fn=<MulBackward0>)\n",
      "tensor(0.0818, grad_fn=<MulBackward0>)\n",
      "tensor(0.0817, grad_fn=<MulBackward0>)\n",
      "tensor(0.0817, grad_fn=<MulBackward0>)\n",
      "tensor(0.0816, grad_fn=<MulBackward0>)\n",
      "tensor(0.0815, grad_fn=<MulBackward0>)\n",
      "tensor(0.0814, grad_fn=<MulBackward0>)\n",
      "tensor(0.0813, grad_fn=<MulBackward0>)\n",
      "tensor(0.0812, grad_fn=<MulBackward0>)\n",
      "tensor(0.0811, grad_fn=<MulBackward0>)\n",
      "tensor(0.0811, grad_fn=<MulBackward0>)\n",
      "tensor(0.0810, grad_fn=<MulBackward0>)\n",
      "tensor(0.0809, grad_fn=<MulBackward0>)\n",
      "tensor(0.0808, grad_fn=<MulBackward0>)\n",
      "tensor(0.0807, grad_fn=<MulBackward0>)\n",
      "tensor(0.0806, grad_fn=<MulBackward0>)\n",
      "tensor(0.0806, grad_fn=<MulBackward0>)\n",
      "tensor(0.0805, grad_fn=<MulBackward0>)\n",
      "tensor(0.0804, grad_fn=<MulBackward0>)\n",
      "tensor(0.0803, grad_fn=<MulBackward0>)\n",
      "tensor(0.0802, grad_fn=<MulBackward0>)\n",
      "tensor(0.0802, grad_fn=<MulBackward0>)\n",
      "tensor(0.0801, grad_fn=<MulBackward0>)\n",
      "tensor(0.0800, grad_fn=<MulBackward0>)\n",
      "tensor(0.0799, grad_fn=<MulBackward0>)\n",
      "tensor(0.0798, grad_fn=<MulBackward0>)\n",
      "tensor(0.0798, grad_fn=<MulBackward0>)\n",
      "tensor(0.0797, grad_fn=<MulBackward0>)\n",
      "tensor(0.0796, grad_fn=<MulBackward0>)\n",
      "tensor(0.0795, grad_fn=<MulBackward0>)\n",
      "tensor(0.0794, grad_fn=<MulBackward0>)\n",
      "tensor(0.0794, grad_fn=<MulBackward0>)\n",
      "tensor(0.0793, grad_fn=<MulBackward0>)\n",
      "tensor(0.0792, grad_fn=<MulBackward0>)\n",
      "tensor(0.0791, grad_fn=<MulBackward0>)\n",
      "tensor(0.0791, grad_fn=<MulBackward0>)\n",
      "tensor(0.0790, grad_fn=<MulBackward0>)\n",
      "tensor(0.0789, grad_fn=<MulBackward0>)\n",
      "tensor(0.0788, grad_fn=<MulBackward0>)\n",
      "tensor(0.0787, grad_fn=<MulBackward0>)\n",
      "tensor(0.0787, grad_fn=<MulBackward0>)\n",
      "tensor(0.0786, grad_fn=<MulBackward0>)\n",
      "tensor(0.0785, grad_fn=<MulBackward0>)\n",
      "tensor(0.0784, grad_fn=<MulBackward0>)\n",
      "tensor(0.0784, grad_fn=<MulBackward0>)\n",
      "tensor(0.0783, grad_fn=<MulBackward0>)\n",
      "tensor(0.0782, grad_fn=<MulBackward0>)\n",
      "tensor(0.0781, grad_fn=<MulBackward0>)\n",
      "tensor(0.0781, grad_fn=<MulBackward0>)\n",
      "tensor(0.0780, grad_fn=<MulBackward0>)\n",
      "tensor(0.0779, grad_fn=<MulBackward0>)\n",
      "tensor(0.0778, grad_fn=<MulBackward0>)\n",
      "tensor(0.0778, grad_fn=<MulBackward0>)\n",
      "tensor(0.0777, grad_fn=<MulBackward0>)\n",
      "tensor(0.0776, grad_fn=<MulBackward0>)\n",
      "tensor(0.0775, grad_fn=<MulBackward0>)\n",
      "tensor(0.0775, grad_fn=<MulBackward0>)\n",
      "tensor(0.0774, grad_fn=<MulBackward0>)\n",
      "tensor(0.0773, grad_fn=<MulBackward0>)\n",
      "tensor(0.0773, grad_fn=<MulBackward0>)\n",
      "tensor(0.0772, grad_fn=<MulBackward0>)\n",
      "tensor(0.0771, grad_fn=<MulBackward0>)\n",
      "tensor(0.0770, grad_fn=<MulBackward0>)\n",
      "tensor(0.0770, grad_fn=<MulBackward0>)\n",
      "tensor(0.0769, grad_fn=<MulBackward0>)\n",
      "tensor(0.0768, grad_fn=<MulBackward0>)\n",
      "tensor(0.0768, grad_fn=<MulBackward0>)\n",
      "tensor(0.0767, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0766, grad_fn=<MulBackward0>)\n",
      "tensor(0.0765, grad_fn=<MulBackward0>)\n",
      "tensor(0.0765, grad_fn=<MulBackward0>)\n",
      "tensor(0.0764, grad_fn=<MulBackward0>)\n",
      "tensor(0.0763, grad_fn=<MulBackward0>)\n",
      "tensor(0.0763, grad_fn=<MulBackward0>)\n",
      "tensor(0.0762, grad_fn=<MulBackward0>)\n",
      "tensor(0.0761, grad_fn=<MulBackward0>)\n",
      "tensor(0.0761, grad_fn=<MulBackward0>)\n",
      "tensor(0.0760, grad_fn=<MulBackward0>)\n",
      "tensor(0.0759, grad_fn=<MulBackward0>)\n",
      "tensor(0.0758, grad_fn=<MulBackward0>)\n",
      "tensor(0.0758, grad_fn=<MulBackward0>)\n",
      "tensor(0.0757, grad_fn=<MulBackward0>)\n",
      "tensor(0.0756, grad_fn=<MulBackward0>)\n",
      "tensor(0.0756, grad_fn=<MulBackward0>)\n",
      "tensor(0.0755, grad_fn=<MulBackward0>)\n",
      "tensor(0.0754, grad_fn=<MulBackward0>)\n",
      "tensor(0.0754, grad_fn=<MulBackward0>)\n",
      "tensor(0.0753, grad_fn=<MulBackward0>)\n",
      "tensor(0.0752, grad_fn=<MulBackward0>)\n",
      "tensor(0.0752, grad_fn=<MulBackward0>)\n",
      "tensor(0.0751, grad_fn=<MulBackward0>)\n",
      "tensor(0.0750, grad_fn=<MulBackward0>)\n",
      "tensor(0.0750, grad_fn=<MulBackward0>)\n",
      "tensor(0.0749, grad_fn=<MulBackward0>)\n",
      "tensor(0.0748, grad_fn=<MulBackward0>)\n",
      "tensor(0.0748, grad_fn=<MulBackward0>)\n",
      "tensor(0.0747, grad_fn=<MulBackward0>)\n",
      "tensor(0.0746, grad_fn=<MulBackward0>)\n",
      "tensor(0.0746, grad_fn=<MulBackward0>)\n",
      "tensor(0.0745, grad_fn=<MulBackward0>)\n",
      "tensor(0.0745, grad_fn=<MulBackward0>)\n",
      "tensor(0.0744, grad_fn=<MulBackward0>)\n",
      "tensor(0.0743, grad_fn=<MulBackward0>)\n",
      "tensor(0.0743, grad_fn=<MulBackward0>)\n",
      "tensor(0.0742, grad_fn=<MulBackward0>)\n",
      "tensor(0.0741, grad_fn=<MulBackward0>)\n",
      "tensor(0.0741, grad_fn=<MulBackward0>)\n",
      "tensor(0.0740, grad_fn=<MulBackward0>)\n",
      "tensor(0.0739, grad_fn=<MulBackward0>)\n",
      "tensor(0.0739, grad_fn=<MulBackward0>)\n",
      "tensor(0.0738, grad_fn=<MulBackward0>)\n",
      "tensor(0.0738, grad_fn=<MulBackward0>)\n",
      "tensor(0.0737, grad_fn=<MulBackward0>)\n",
      "tensor(0.0736, grad_fn=<MulBackward0>)\n",
      "tensor(0.0736, grad_fn=<MulBackward0>)\n",
      "tensor(0.0735, grad_fn=<MulBackward0>)\n",
      "tensor(0.0734, grad_fn=<MulBackward0>)\n",
      "tensor(0.0734, grad_fn=<MulBackward0>)\n",
      "tensor(0.0733, grad_fn=<MulBackward0>)\n",
      "tensor(0.0733, grad_fn=<MulBackward0>)\n",
      "tensor(0.0732, grad_fn=<MulBackward0>)\n",
      "tensor(0.0731, grad_fn=<MulBackward0>)\n",
      "tensor(0.0731, grad_fn=<MulBackward0>)\n",
      "tensor(0.0730, grad_fn=<MulBackward0>)\n",
      "tensor(0.0729, grad_fn=<MulBackward0>)\n",
      "tensor(0.0729, grad_fn=<MulBackward0>)\n",
      "tensor(0.0728, grad_fn=<MulBackward0>)\n",
      "tensor(0.0728, grad_fn=<MulBackward0>)\n",
      "tensor(0.0727, grad_fn=<MulBackward0>)\n",
      "tensor(0.0726, grad_fn=<MulBackward0>)\n",
      "tensor(0.0726, grad_fn=<MulBackward0>)\n",
      "tensor(0.0725, grad_fn=<MulBackward0>)\n",
      "tensor(0.0725, grad_fn=<MulBackward0>)\n",
      "tensor(0.0724, grad_fn=<MulBackward0>)\n",
      "tensor(0.0723, grad_fn=<MulBackward0>)\n",
      "tensor(0.0723, grad_fn=<MulBackward0>)\n",
      "tensor(0.0722, grad_fn=<MulBackward0>)\n",
      "tensor(0.0722, grad_fn=<MulBackward0>)\n",
      "tensor(0.0721, grad_fn=<MulBackward0>)\n",
      "tensor(0.0720, grad_fn=<MulBackward0>)\n",
      "tensor(0.0720, grad_fn=<MulBackward0>)\n",
      "tensor(0.0719, grad_fn=<MulBackward0>)\n",
      "tensor(0.0719, grad_fn=<MulBackward0>)\n",
      "tensor(0.0718, grad_fn=<MulBackward0>)\n",
      "tensor(0.0718, grad_fn=<MulBackward0>)\n",
      "tensor(0.0717, grad_fn=<MulBackward0>)\n",
      "tensor(0.0716, grad_fn=<MulBackward0>)\n",
      "tensor(0.0716, grad_fn=<MulBackward0>)\n",
      "tensor(0.0715, grad_fn=<MulBackward0>)\n",
      "tensor(0.0715, grad_fn=<MulBackward0>)\n",
      "tensor(0.0714, grad_fn=<MulBackward0>)\n",
      "tensor(0.0714, grad_fn=<MulBackward0>)\n",
      "tensor(0.0713, grad_fn=<MulBackward0>)\n",
      "tensor(0.0712, grad_fn=<MulBackward0>)\n",
      "tensor(0.0712, grad_fn=<MulBackward0>)\n",
      "tensor(0.0711, grad_fn=<MulBackward0>)\n",
      "tensor(0.0711, grad_fn=<MulBackward0>)\n",
      "tensor(0.0710, grad_fn=<MulBackward0>)\n",
      "tensor(0.0710, grad_fn=<MulBackward0>)\n",
      "tensor(0.0709, grad_fn=<MulBackward0>)\n",
      "tensor(0.0708, grad_fn=<MulBackward0>)\n",
      "tensor(0.0708, grad_fn=<MulBackward0>)\n",
      "tensor(0.0707, grad_fn=<MulBackward0>)\n",
      "tensor(0.0707, grad_fn=<MulBackward0>)\n",
      "tensor(0.0706, grad_fn=<MulBackward0>)\n",
      "tensor(0.0706, grad_fn=<MulBackward0>)\n",
      "tensor(0.0705, grad_fn=<MulBackward0>)\n",
      "tensor(0.0705, grad_fn=<MulBackward0>)\n",
      "tensor(0.0704, grad_fn=<MulBackward0>)\n",
      "tensor(0.0704, grad_fn=<MulBackward0>)\n",
      "tensor(0.0703, grad_fn=<MulBackward0>)\n",
      "tensor(0.0702, grad_fn=<MulBackward0>)\n",
      "tensor(0.0702, grad_fn=<MulBackward0>)\n",
      "tensor(0.0701, grad_fn=<MulBackward0>)\n",
      "tensor(0.0701, grad_fn=<MulBackward0>)\n",
      "tensor(0.0700, grad_fn=<MulBackward0>)\n",
      "tensor(0.0700, grad_fn=<MulBackward0>)\n",
      "tensor(0.0699, grad_fn=<MulBackward0>)\n",
      "tensor(0.0699, grad_fn=<MulBackward0>)\n",
      "tensor(0.0698, grad_fn=<MulBackward0>)\n",
      "tensor(0.0698, grad_fn=<MulBackward0>)\n",
      "tensor(0.0697, grad_fn=<MulBackward0>)\n",
      "tensor(0.0697, grad_fn=<MulBackward0>)\n",
      "tensor(0.0696, grad_fn=<MulBackward0>)\n",
      "tensor(0.0695, grad_fn=<MulBackward0>)\n",
      "tensor(0.0695, grad_fn=<MulBackward0>)\n",
      "tensor(0.0694, grad_fn=<MulBackward0>)\n",
      "tensor(0.0694, grad_fn=<MulBackward0>)\n",
      "tensor(0.0693, grad_fn=<MulBackward0>)\n",
      "tensor(0.0693, grad_fn=<MulBackward0>)\n",
      "tensor(0.0692, grad_fn=<MulBackward0>)\n",
      "tensor(0.0692, grad_fn=<MulBackward0>)\n",
      "tensor(0.0691, grad_fn=<MulBackward0>)\n",
      "tensor(0.0691, grad_fn=<MulBackward0>)\n",
      "tensor(0.0690, grad_fn=<MulBackward0>)\n",
      "tensor(0.0690, grad_fn=<MulBackward0>)\n",
      "tensor(0.0689, grad_fn=<MulBackward0>)\n",
      "tensor(0.0689, grad_fn=<MulBackward0>)\n",
      "tensor(0.0688, grad_fn=<MulBackward0>)\n",
      "tensor(0.0688, grad_fn=<MulBackward0>)\n",
      "tensor(0.0687, grad_fn=<MulBackward0>)\n",
      "tensor(0.0687, grad_fn=<MulBackward0>)\n",
      "tensor(0.0686, grad_fn=<MulBackward0>)\n",
      "tensor(0.0686, grad_fn=<MulBackward0>)\n",
      "tensor(0.0685, grad_fn=<MulBackward0>)\n",
      "tensor(0.0685, grad_fn=<MulBackward0>)\n",
      "tensor(0.0684, grad_fn=<MulBackward0>)\n",
      "tensor(0.0684, grad_fn=<MulBackward0>)\n",
      "tensor(0.0683, grad_fn=<MulBackward0>)\n",
      "tensor(0.0683, grad_fn=<MulBackward0>)\n",
      "tensor(0.0682, grad_fn=<MulBackward0>)\n",
      "tensor(0.0682, grad_fn=<MulBackward0>)\n",
      "tensor(0.0681, grad_fn=<MulBackward0>)\n",
      "tensor(0.0681, grad_fn=<MulBackward0>)\n",
      "tensor(0.0680, grad_fn=<MulBackward0>)\n",
      "tensor(0.0680, grad_fn=<MulBackward0>)\n",
      "tensor(0.0679, grad_fn=<MulBackward0>)\n",
      "tensor(0.0679, grad_fn=<MulBackward0>)\n",
      "tensor(0.0678, grad_fn=<MulBackward0>)\n",
      "tensor(0.0678, grad_fn=<MulBackward0>)\n",
      "tensor(0.0677, grad_fn=<MulBackward0>)\n",
      "tensor(0.0677, grad_fn=<MulBackward0>)\n",
      "tensor(0.0676, grad_fn=<MulBackward0>)\n",
      "tensor(0.0676, grad_fn=<MulBackward0>)\n",
      "tensor(0.0675, grad_fn=<MulBackward0>)\n",
      "tensor(0.0675, grad_fn=<MulBackward0>)\n",
      "tensor(0.0674, grad_fn=<MulBackward0>)\n",
      "tensor(0.0674, grad_fn=<MulBackward0>)\n",
      "tensor(0.0673, grad_fn=<MulBackward0>)\n",
      "tensor(0.0673, grad_fn=<MulBackward0>)\n",
      "tensor(0.0672, grad_fn=<MulBackward0>)\n",
      "tensor(0.0672, grad_fn=<MulBackward0>)\n",
      "tensor(0.0671, grad_fn=<MulBackward0>)\n",
      "tensor(0.0671, grad_fn=<MulBackward0>)\n",
      "tensor(0.0670, grad_fn=<MulBackward0>)\n",
      "tensor(0.0670, grad_fn=<MulBackward0>)\n",
      "tensor(0.0670, grad_fn=<MulBackward0>)\n",
      "tensor(0.0669, grad_fn=<MulBackward0>)\n",
      "tensor(0.0669, grad_fn=<MulBackward0>)\n",
      "tensor(0.0668, grad_fn=<MulBackward0>)\n",
      "tensor(0.0668, grad_fn=<MulBackward0>)\n",
      "tensor(0.0667, grad_fn=<MulBackward0>)\n",
      "tensor(0.0667, grad_fn=<MulBackward0>)\n",
      "tensor(0.0666, grad_fn=<MulBackward0>)\n",
      "tensor(0.0666, grad_fn=<MulBackward0>)\n",
      "tensor(0.0665, grad_fn=<MulBackward0>)\n",
      "tensor(0.0665, grad_fn=<MulBackward0>)\n",
      "tensor(0.0664, grad_fn=<MulBackward0>)\n",
      "tensor(0.0664, grad_fn=<MulBackward0>)\n",
      "tensor(0.0663, grad_fn=<MulBackward0>)\n",
      "tensor(0.0663, grad_fn=<MulBackward0>)\n",
      "tensor(0.0663, grad_fn=<MulBackward0>)\n",
      "tensor(0.0662, grad_fn=<MulBackward0>)\n",
      "tensor(0.0662, grad_fn=<MulBackward0>)\n",
      "tensor(0.0661, grad_fn=<MulBackward0>)\n",
      "tensor(0.0661, grad_fn=<MulBackward0>)\n",
      "tensor(0.0660, grad_fn=<MulBackward0>)\n",
      "tensor(0.0660, grad_fn=<MulBackward0>)\n",
      "tensor(0.0659, grad_fn=<MulBackward0>)\n",
      "tensor(0.0659, grad_fn=<MulBackward0>)\n",
      "tensor(0.0658, grad_fn=<MulBackward0>)\n",
      "tensor(0.0658, grad_fn=<MulBackward0>)\n",
      "tensor(0.0658, grad_fn=<MulBackward0>)\n",
      "tensor(0.0657, grad_fn=<MulBackward0>)\n",
      "tensor(0.0657, grad_fn=<MulBackward0>)\n",
      "tensor(0.0656, grad_fn=<MulBackward0>)\n",
      "tensor(0.0656, grad_fn=<MulBackward0>)\n",
      "tensor(0.0655, grad_fn=<MulBackward0>)\n",
      "tensor(0.0655, grad_fn=<MulBackward0>)\n",
      "tensor(0.0654, grad_fn=<MulBackward0>)\n",
      "tensor(0.0654, grad_fn=<MulBackward0>)\n",
      "tensor(0.0654, grad_fn=<MulBackward0>)\n",
      "tensor(0.0653, grad_fn=<MulBackward0>)\n",
      "tensor(0.0653, grad_fn=<MulBackward0>)\n",
      "tensor(0.0652, grad_fn=<MulBackward0>)\n",
      "tensor(0.0652, grad_fn=<MulBackward0>)\n",
      "tensor(0.0651, grad_fn=<MulBackward0>)\n",
      "tensor(0.0651, grad_fn=<MulBackward0>)\n",
      "tensor(0.0650, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0650, grad_fn=<MulBackward0>)\n",
      "tensor(0.0650, grad_fn=<MulBackward0>)\n",
      "tensor(0.0649, grad_fn=<MulBackward0>)\n",
      "tensor(0.0649, grad_fn=<MulBackward0>)\n",
      "tensor(0.0648, grad_fn=<MulBackward0>)\n",
      "tensor(0.0648, grad_fn=<MulBackward0>)\n",
      "tensor(0.0647, grad_fn=<MulBackward0>)\n",
      "tensor(0.0647, grad_fn=<MulBackward0>)\n",
      "tensor(0.0647, grad_fn=<MulBackward0>)\n",
      "tensor(0.0646, grad_fn=<MulBackward0>)\n",
      "tensor(0.0646, grad_fn=<MulBackward0>)\n",
      "tensor(0.0645, grad_fn=<MulBackward0>)\n",
      "tensor(0.0645, grad_fn=<MulBackward0>)\n",
      "tensor(0.0644, grad_fn=<MulBackward0>)\n",
      "tensor(0.0644, grad_fn=<MulBackward0>)\n",
      "tensor(0.0644, grad_fn=<MulBackward0>)\n",
      "tensor(0.0643, grad_fn=<MulBackward0>)\n",
      "tensor(0.0643, grad_fn=<MulBackward0>)\n",
      "tensor(0.0642, grad_fn=<MulBackward0>)\n",
      "tensor(0.0642, grad_fn=<MulBackward0>)\n",
      "tensor(0.0641, grad_fn=<MulBackward0>)\n",
      "tensor(0.0641, grad_fn=<MulBackward0>)\n",
      "tensor(0.0641, grad_fn=<MulBackward0>)\n",
      "tensor(0.0640, grad_fn=<MulBackward0>)\n",
      "tensor(0.0640, grad_fn=<MulBackward0>)\n",
      "tensor(0.0639, grad_fn=<MulBackward0>)\n",
      "tensor(0.0639, grad_fn=<MulBackward0>)\n",
      "tensor(0.0639, grad_fn=<MulBackward0>)\n",
      "tensor(0.0638, grad_fn=<MulBackward0>)\n",
      "tensor(0.0638, grad_fn=<MulBackward0>)\n",
      "tensor(0.0637, grad_fn=<MulBackward0>)\n",
      "tensor(0.0637, grad_fn=<MulBackward0>)\n",
      "tensor(0.0636, grad_fn=<MulBackward0>)\n",
      "tensor(0.0636, grad_fn=<MulBackward0>)\n",
      "tensor(0.0636, grad_fn=<MulBackward0>)\n",
      "tensor(0.0635, grad_fn=<MulBackward0>)\n",
      "tensor(0.0635, grad_fn=<MulBackward0>)\n",
      "tensor(0.0634, grad_fn=<MulBackward0>)\n",
      "tensor(0.0634, grad_fn=<MulBackward0>)\n",
      "tensor(0.0634, grad_fn=<MulBackward0>)\n",
      "tensor(0.0633, grad_fn=<MulBackward0>)\n",
      "tensor(0.0633, grad_fn=<MulBackward0>)\n",
      "tensor(0.0632, grad_fn=<MulBackward0>)\n",
      "tensor(0.0632, grad_fn=<MulBackward0>)\n",
      "tensor(0.0632, grad_fn=<MulBackward0>)\n",
      "tensor(0.0631, grad_fn=<MulBackward0>)\n",
      "tensor(0.0631, grad_fn=<MulBackward0>)\n",
      "tensor(0.0630, grad_fn=<MulBackward0>)\n",
      "tensor(0.0630, grad_fn=<MulBackward0>)\n",
      "tensor(0.0630, grad_fn=<MulBackward0>)\n",
      "tensor(0.0629, grad_fn=<MulBackward0>)\n",
      "tensor(0.0629, grad_fn=<MulBackward0>)\n",
      "tensor(0.0628, grad_fn=<MulBackward0>)\n",
      "tensor(0.0628, grad_fn=<MulBackward0>)\n",
      "tensor(0.0628, grad_fn=<MulBackward0>)\n",
      "tensor(0.0627, grad_fn=<MulBackward0>)\n",
      "tensor(0.0627, grad_fn=<MulBackward0>)\n",
      "tensor(0.0626, grad_fn=<MulBackward0>)\n",
      "tensor(0.0626, grad_fn=<MulBackward0>)\n",
      "tensor(0.0626, grad_fn=<MulBackward0>)\n",
      "tensor(0.0625, grad_fn=<MulBackward0>)\n",
      "tensor(0.0625, grad_fn=<MulBackward0>)\n",
      "tensor(0.0624, grad_fn=<MulBackward0>)\n",
      "tensor(0.0624, grad_fn=<MulBackward0>)\n",
      "tensor(0.0624, grad_fn=<MulBackward0>)\n",
      "tensor(0.0623, grad_fn=<MulBackward0>)\n",
      "tensor(0.0623, grad_fn=<MulBackward0>)\n",
      "tensor(0.0622, grad_fn=<MulBackward0>)\n",
      "tensor(0.0622, grad_fn=<MulBackward0>)\n",
      "tensor(0.0622, grad_fn=<MulBackward0>)\n",
      "tensor(0.0621, grad_fn=<MulBackward0>)\n",
      "tensor(0.0621, grad_fn=<MulBackward0>)\n",
      "tensor(0.0621, grad_fn=<MulBackward0>)\n",
      "tensor(0.0620, grad_fn=<MulBackward0>)\n",
      "tensor(0.0620, grad_fn=<MulBackward0>)\n",
      "tensor(0.0619, grad_fn=<MulBackward0>)\n",
      "tensor(0.0619, grad_fn=<MulBackward0>)\n",
      "tensor(0.0619, grad_fn=<MulBackward0>)\n",
      "tensor(0.0618, grad_fn=<MulBackward0>)\n",
      "tensor(0.0618, grad_fn=<MulBackward0>)\n",
      "tensor(0.0617, grad_fn=<MulBackward0>)\n",
      "tensor(0.0617, grad_fn=<MulBackward0>)\n",
      "tensor(0.0617, grad_fn=<MulBackward0>)\n",
      "tensor(0.0616, grad_fn=<MulBackward0>)\n",
      "tensor(0.0616, grad_fn=<MulBackward0>)\n",
      "tensor(0.0616, grad_fn=<MulBackward0>)\n",
      "tensor(0.0615, grad_fn=<MulBackward0>)\n",
      "tensor(0.0615, grad_fn=<MulBackward0>)\n",
      "tensor(0.0614, grad_fn=<MulBackward0>)\n",
      "tensor(0.0614, grad_fn=<MulBackward0>)\n",
      "tensor(0.0614, grad_fn=<MulBackward0>)\n",
      "tensor(0.0613, grad_fn=<MulBackward0>)\n",
      "tensor(0.0613, grad_fn=<MulBackward0>)\n",
      "tensor(0.0613, grad_fn=<MulBackward0>)\n",
      "tensor(0.0612, grad_fn=<MulBackward0>)\n",
      "tensor(0.0612, grad_fn=<MulBackward0>)\n",
      "tensor(0.0611, grad_fn=<MulBackward0>)\n",
      "tensor(0.0611, grad_fn=<MulBackward0>)\n",
      "tensor(0.0611, grad_fn=<MulBackward0>)\n",
      "tensor(0.0610, grad_fn=<MulBackward0>)\n",
      "tensor(0.0610, grad_fn=<MulBackward0>)\n",
      "tensor(0.0610, grad_fn=<MulBackward0>)\n",
      "tensor(0.0609, grad_fn=<MulBackward0>)\n",
      "tensor(0.0609, grad_fn=<MulBackward0>)\n",
      "tensor(0.0609, grad_fn=<MulBackward0>)\n",
      "tensor(0.0608, grad_fn=<MulBackward0>)\n",
      "tensor(0.0608, grad_fn=<MulBackward0>)\n",
      "tensor(0.0607, grad_fn=<MulBackward0>)\n",
      "tensor(0.0607, grad_fn=<MulBackward0>)\n",
      "tensor(0.0607, grad_fn=<MulBackward0>)\n",
      "tensor(0.0606, grad_fn=<MulBackward0>)\n",
      "tensor(0.0606, grad_fn=<MulBackward0>)\n",
      "tensor(0.0606, grad_fn=<MulBackward0>)\n",
      "tensor(0.0605, grad_fn=<MulBackward0>)\n",
      "tensor(0.0605, grad_fn=<MulBackward0>)\n",
      "tensor(0.0604, grad_fn=<MulBackward0>)\n",
      "tensor(0.0604, grad_fn=<MulBackward0>)\n",
      "tensor(0.0604, grad_fn=<MulBackward0>)\n",
      "tensor(0.0603, grad_fn=<MulBackward0>)\n",
      "tensor(0.0603, grad_fn=<MulBackward0>)\n",
      "tensor(0.0603, grad_fn=<MulBackward0>)\n",
      "tensor(0.0602, grad_fn=<MulBackward0>)\n",
      "tensor(0.0602, grad_fn=<MulBackward0>)\n",
      "tensor(0.0602, grad_fn=<MulBackward0>)\n",
      "tensor(0.0601, grad_fn=<MulBackward0>)\n",
      "tensor(0.0601, grad_fn=<MulBackward0>)\n",
      "tensor(0.0601, grad_fn=<MulBackward0>)\n",
      "tensor(0.0600, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# fit a point\n",
    "resnet, out_size = initialize_resnet_model()\n",
    "bottleneck = initialize_bottleneck(2*out_size)\n",
    "decoder = initialize_decoder()\n",
    "print(resnet)\n",
    "print(bottleneck)\n",
    "print(decoder)\n",
    "last_prediction, losses = fit_one_point(resnet, bottleneck, decoder, batched_point, data_transforms['train_in'], data_transforms['train_target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eac13442",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 512, 512) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-58da198e96ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.plot(losses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2731\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    711\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 712\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 512, 512) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(last_prediction[0].detach().numpy())\n",
    "#plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb29fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = get_dataloaders(1)\n",
    "#print(dataloaders_dict)\n",
    "\n",
    "point = dataloaders_dict['train']\n",
    "\n",
    "\n",
    "# overfit a point\n",
    "print(point)\n",
    "since = time.time()\n",
    "\n",
    "val_acc_history = []\n",
    "\n",
    "best_model_wts = copy.deepcopy(resnet.state_dict())\n",
    "best_loss = 0.0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    resnet.train()\n",
    "    # Each epoch has a training and validation phase\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    # TQDM has nice progress bars\n",
    "    for inputs, _ in tqdm(dataloaders[phase]):\n",
    "        #inputs2 = data_transforms['train'](inputs)\n",
    "        # we get 10, 720, 1280, 3\n",
    "        # for now, lets just get a single frame\n",
    "        # perform transform on input\n",
    "        transformed_input = data_transforms[phase](inputs)\n",
    "        label = inputs # this makes sense, should we perform any transforms?\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            prediction = model(inputs)\n",
    "            preceptual_loss = percept(prediction, label)\n",
    "            mse_loss = nn.mse(prediction, label)\n",
    "            loss = alpha * perceptual_loss + beta * mse_loss\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        print(inputs2.shape)\n",
    "\n",
    "\n",
    "for inputs, _ in tqdm(dataloaders_dict['val']):\n",
    "    print(inputs.shape)\n",
    "    inputs2 = data_transforms['train'](inputs)\n",
    "\n",
    "    print(inputs2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd956d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
